"""
CLAUDE PROVIDER - Integra√ß√£o com Anthropic Claude
Provider especializado em racioc√≠nio complexo e an√°lise
"""

import asyncio
import json
import time
import logging
from typing import Dict, List, Optional, Any, AsyncGenerator
from dataclasses import dataclass
from enum import Enum
import anthropic
from anthropic import AsyncAnthropic

logger = logging.getLogger('ClaudeProvider')

@dataclass
class ClaudeConfig:
    """Configura√ß√£o do Claude"""
    api_key: str
    model: str = "claude-3-opus-20240229"
    max_tokens: int = 4096
    temperature: float = 0.7
    top_p: float = 1.0
    top_k: int = 40
    timeout: int = 30
    max_retries: int = 3
    rate_limit: int = 100  # requests por minuto

@dataclass
class ClaudeResponse:
    """Resposta do Claude"""
    content: str
    model: str
    tokens_input: int
    tokens_output: int
    latency: float
    cost: float
    metadata: Dict[str, Any]

class ClaudeProvider:
    """
    Provider para Anthropic Claude
    Especializado em racioc√≠nio complexo, an√°lise e planejamento
    """
    
    CAPABILITIES = [
        'complex_reasoning',
        'analysis',
        'planning',
        'coding',
        'mathematics',
        'creative_writing',
        'ethical_reasoning',
        'multi_turn_dialogue'
    ]
    
    COST_PER_1K_INPUT = 0.015
    COST_PER_1K_OUTPUT = 0.075
    
    def __init__(self, config: ClaudeConfig):
        self.config = config
        self.client = AsyncAnthropic(api_key=config.api_key)
        self.sync_client = anthropic.Anthropic(api_key=config.api_key)
        
        # Rate limiting
        self.request_times: List[float] = []
        self.rate_limit = config.rate_limit
        
        # Cache de system prompts
        self.system_prompts = self._load_system_prompts()
        
        logger.info(f"‚úÖ Claude Provider initialized with model {config.model}")
    
    def _load_system_prompts(self) -> Dict[str, str]:
        """Carrega system prompts otimizados para diferentes tarefas"""
        return {
            'default': """Voc√™ √© Claude, um assistente IA avan√ßado criado pela Anthropic.
Voc√™ √© especializado em racioc√≠nio complexo, an√°lise profunda e resolu√ß√£o de problemas.
Sempre forne√ßa respostas precisas, bem estruturadas e √∫teis.""",
            
            'analysis': """Voc√™ √© um analista especializado. 
Analise profundamente os dados fornecidos, identifique padr√µes, insights e conclus√µes.
Use racioc√≠nio estruturado e apresente suas descobertas de forma clara e organizada.""",
            
            'coding': """Voc√™ √© um programador expert em m√∫ltiplas linguagens.
Escreva c√≥digo limpo, eficiente e bem documentado.
Sempre inclua tratamento de erros e considere edge cases.""",
            
            'planning': """Voc√™ √© um planejador estrat√©gico especializado.
Crie planos detalhados, considerando depend√™ncias, riscos e alternativas.
Organize as tarefas em ordem l√≥gica e estime tempos realistas.""",
            
            'creative': """Voc√™ √© um escritor criativo e storyteller.
Crie conte√∫do original, envolvente e bem escrito.
Mantenha consist√™ncia de tom e estilo ao longo do texto."""
        }
    
    async def complete(
        self,
        prompt: str,
        system_prompt: str = None,
        context: List[Dict[str, str]] = None,
        stream: bool = False,
        **kwargs
    ) -> ClaudeResponse:
        """Gera completion com Claude"""
        
        # Rate limiting
        await self._check_rate_limit()
        
        # Prepara mensagens
        messages = self._prepare_messages(prompt, context)
        
        # System prompt
        if not system_prompt:
            system_prompt = self.system_prompts['default']
        
        # Par√¢metros
        params = {
            'model': self.config.model,
            'messages': messages,
            'system': system_prompt,
            'max_tokens': kwargs.get('max_tokens', self.config.max_tokens),
            'temperature': kwargs.get('temperature', self.config.temperature),
            'top_p': kwargs.get('top_p', self.config.top_p),
            'top_k': kwargs.get('top_k', self.config.top_k)
        }
        
        start_time = time.time()
        
        try:
            if stream:
                return await self._stream_completion(params)
            else:
                response = await self.client.messages.create(**params)
                
                latency = time.time() - start_time
                
                # Calcula custos
                input_cost = (response.usage.input_tokens / 1000) * self.COST_PER_1K_INPUT
                output_cost = (response.usage.output_tokens / 1000) * self.COST_PER_1K_OUTPUT
                
                return ClaudeResponse(
                    content=response.content[0].text,
                    model=response.model,
                    tokens_input=response.usage.input_tokens,
                    tokens_output=response.usage.output_tokens,
                    latency=latency,
                    cost=input_cost + output_cost,
                    metadata={
                        'stop_reason': response.stop_reason,
                        'id': response.id
                    }
                )
                
        except Exception as e:
            logger.error(f"Claude completion failed: {e}")
            raise
    
    async def _stream_completion(self, params: Dict) -> AsyncGenerator[str, None]:
        """Stream de completion"""
        try:
            async with self.client.messages.stream(**params) as stream:
                async for chunk in stream:
                    if chunk.type == 'content_block_delta':
                        yield chunk.delta.text
        except Exception as e:
            logger.error(f"Claude streaming failed: {e}")
            raise
    
    def _prepare_messages(
        self,
        prompt: str,
        context: List[Dict[str, str]] = None
    ) -> List[Dict[str, str]]:
        """Prepara mensagens para a API"""
        messages = []
        
        # Adiciona contexto se existir
        if context:
            for msg in context:
                messages.append({
                    'role': msg.get('role', 'user'),
                    'content': msg.get('content', '')
                })
        
        # Adiciona prompt atual
        messages.append({
            'role': 'user',
            'content': prompt
        })
        
        return messages
    
    async def analyze(
        self,
        data: Any,
        analysis_type: str = 'general',
        format: str = 'markdown'
    ) -> Dict[str, Any]:
        """Realiza an√°lise especializada"""
        
        analysis_prompts = {
            'general': "Analise os seguintes dados e forne√ßa insights detalhados:",
            'statistical': "Realize an√°lise estat√≠stica dos dados, identificando m√©dias, tend√™ncias e outliers:",
            'sentiment': "Analise o sentimento e tom emocional do seguinte conte√∫do:",
            'comparative': "Compare e contraste os seguintes elementos, destacando diferen√ßas e semelhan√ßas:",
            'swot': "Realize an√°lise SWOT (For√ßas, Fraquezas, Oportunidades, Amea√ßas) para:",
            'root_cause': "Identifique as causas raiz e fatores contribuintes para:"
        }
        
        prompt = f"{analysis_prompts.get(analysis_type, analysis_prompts['general'])}\n\n{json.dumps(data, indent=2)}"
        
        if format == 'json':
            prompt += "\n\nFormate a resposta como JSON estruturado."
        elif format == 'bullet_points':
            prompt += "\n\nFormate a resposta em bullet points organizados."
        
        response = await self.complete(
            prompt=prompt,
            system_prompt=self.system_prompts['analysis'],
            temperature=0.5  # Mais determin√≠stico para an√°lise
        )
        
        # Parse se JSON
        if format == 'json':
            try:
                return json.loads(response.content)
            except:
                return {'analysis': response.content}
        
        return {
            'analysis': response.content,
            'tokens_used': response.tokens_input + response.tokens_output,
            'cost': response.cost
        }
    
    async def plan(
        self,
        objective: str,
        constraints: List[str] = None,
        resources: List[str] = None
    ) -> Dict[str, Any]:
        """Cria plano de execu√ß√£o detalhado"""
        
        prompt = f"""Crie um plano detalhado para alcan√ßar o seguinte objetivo:

OBJETIVO: {objective}

RESTRI√á√ïES:
{chr(10).join(f'- {c}' for c in (constraints or ['Nenhuma restri√ß√£o espec√≠fica']))}

RECURSOS DISPON√çVEIS:
{chr(10).join(f'- {r}' for r in (resources or ['Recursos padr√£o']))}

Formate o plano com:
1. Vis√£o geral
2. Fases principais
3. Tarefas espec√≠ficas por fase
4. Depend√™ncias entre tarefas
5. Estimativa de tempo
6. Riscos e mitiga√ß√µes
7. Crit√©rios de sucesso
"""
        
        response = await self.complete(
            prompt=prompt,
            system_prompt=self.system_prompts['planning'],
            temperature=0.6,
            max_tokens=2000
        )
        
        return {
            'plan': response.content,
            'tokens_used': response.tokens_input + response.tokens_output,
            'cost': response.cost,
            'model': response.model
        }
    
    async def code(
        self,
        task: str,
        language: str = 'python',
        context: str = None,
        requirements: List[str] = None
    ) -> Dict[str, Any]:
        """Gera c√≥digo"""
        
        prompt = f"""Escreva c√≥digo {language} para: {task}

REQUISITOS:
{chr(10).join(f'- {r}' for r in (requirements or ['C√≥digo limpo e eficiente']))}

{f'CONTEXTO ADICIONAL: {context}' if context else ''}

Inclua:
- Documenta√ß√£o completa
- Tratamento de erros
- Type hints (se aplic√°vel)
- Testes unit√°rios b√°sicos
"""
        
        response = await self.complete(
            prompt=prompt,
            system_prompt=self.system_prompts['coding'],
            temperature=0.3,  # Mais determin√≠stico para c√≥digo
            max_tokens=3000
        )
        
        # Extrai c√≥digo da resposta
        code_blocks = self._extract_code_blocks(response.content)
        
        return {
            'code': code_blocks,
            'explanation': response.content,
            'tokens_used': response.tokens_input + response.tokens_output,
            'cost': response.cost
        }
    
    def _extract_code_blocks(self, text: str) -> List[Dict[str, str]]:
        """Extrai blocos de c√≥digo da resposta"""
        import re
        
        blocks = []
        pattern = r'```(\w+)?\n(.*?)```'
        matches = re.findall(pattern, text, re.DOTALL)
        
        for lang, code in matches:
            blocks.append({
                'language': lang or 'text',
                'code': code.strip()
            })
        
        return blocks
    
    async def reason(
        self,
        problem: str,
        approach: str = 'step_by_step'
    ) -> Dict[str, Any]:
        """Racioc√≠nio complexo sobre problema"""
        
        approaches = {
            'step_by_step': """Resolva este problema passo a passo:
1. Entenda o problema completamente
2. Identifique informa√ß√µes chave
3. Desenvolva uma abordagem
4. Execute cada passo
5. Verifique a solu√ß√£o""",
            
            'first_principles': """Use racioc√≠nio de primeiros princ√≠pios:
1. Identifique as suposi√ß√µes fundamentais
2. Questione cada suposi√ß√£o
3. Reconstrua do zero com fatos b√°sicos
4. Derive a solu√ß√£o dos fundamentos""",
            
            'dialectical': """Use racioc√≠nio dial√©tico:
1. Apresente a tese
2. Explore a ant√≠tese
3. Sintetize uma solu√ß√£o superior
4. Considere implica√ß√µes""",
            
            'systems_thinking': """Use pensamento sist√™mico:
1. Identifique todos os componentes
2. Mapeie as intera√ß√µes
3. Encontre loops de feedback
4. Considere efeitos de segunda ordem
5. Proponha interven√ß√µes"""
        }
        
        prompt = f"{approaches.get(approach, approaches['step_by_step'])}\n\nPROBLEMA: {problem}"
        
        response = await self.complete(
            prompt=prompt,
            temperature=0.7,
            max_tokens=2500
        )
        
        return {
            'reasoning': response.content,
            'approach': approach,
            'tokens_used': response.tokens_input + response.tokens_output,
            'cost': response.cost
        }
    
    async def _check_rate_limit(self):
        """Verifica e aplica rate limiting"""
        current_time = time.time()
        
        # Remove requests antigas
        self.request_times = [
            t for t in self.request_times 
            if current_time - t < 60
        ]
        
        # Verifica limite
        if len(self.request_times) >= self.rate_limit:
            sleep_time = 60 - (current_time - self.request_times[0])
            if sleep_time > 0:
                logger.info(f"Rate limit reached, sleeping {sleep_time:.2f}s")
                await asyncio.sleep(sleep_time)
        
        self.request_times.append(current_time)
    
    def estimate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """Estima custo da requisi√ß√£o"""
        input_cost = (input_tokens / 1000) * self.COST_PER_1K_INPUT
        output_cost = (output_tokens / 1000) * self.COST_PER_1K_OUTPUT
        return input_cost + output_cost
    
    def get_capabilities(self) -> List[str]:
        """Retorna capacidades do provider"""
        return self.CAPABILITIES
    
    async def health_check(self) -> Dict[str, Any]:
        """Verifica sa√∫de do provider"""
        try:
            response = await self.complete(
                prompt="Responda apenas 'OK' se est√° funcionando",
                max_tokens=10
            )
            
            return {
                'status': 'healthy' if 'OK' in response.content else 'degraded',
                'model': self.config.model,
                'latency': response.latency,
                'timestamp': time.time()
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e),
                'timestamp': time.time()
            }

# ============================================================================
# EXEMPLO DE USO
# ============================================================================

async def example_usage():
    """Demonstra uso do Claude Provider"""
    
    # Configura√ß√£o
    config = ClaudeConfig(
        api_key="sua-api-key-aqui",
        model="claude-3-opus-20240229",
        max_tokens=1000
    )
    
    # Cria provider
    claude = ClaudeProvider(config)
    
    # Testa diferentes capacidades
    print("üß† Testando Claude Provider\n")
    
    # 1. Completion simples
    print("1. Completion simples:")
    response = await claude.complete(
        prompt="Explique a diferen√ßa entre CPU e GPU em 3 frases"
    )
    print(f"Resposta: {response.content}")
    print(f"Tokens: {response.tokens_input} + {response.tokens_output}")
    print(f"Custo: ${response.cost:.4f}\n")
    
    # 2. An√°lise de dados
    print("2. An√°lise de dados:")
    analysis = await claude.analyze(
        data={
            'vendas': [100, 150, 120, 180, 200, 190, 220],
            'meses': ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul']
        },
        analysis_type='statistical'
    )
    print(f"An√°lise: {analysis['analysis'][:200]}...\n")
    
    # 3. Planejamento
    print("3. Planejamento:")
    plan = await claude.plan(
        objective="Criar um site e-commerce em 30 dias",
        constraints=["Or√ßamento de R$10.000", "Equipe de 2 pessoas"],
        resources=["React", "Node.js", "PostgreSQL"]
    )
    print(f"Plano: {plan['plan'][:300]}...\n")
    
    # 4. Gera√ß√£o de c√≥digo
    print("4. Gera√ß√£o de c√≥digo:")
    code = await claude.code(
        task="Fun√ß√£o para validar CPF brasileiro",
        language="python",
        requirements=["Deve aceitar com ou sem formata√ß√£o", "Retornar True/False"]
    )
    if code['code']:
        print(f"C√≥digo gerado: {code['code'][0]['code'][:200]}...\n")
    
    # 5. Health check
    print("5. Health check:")
    health = await claude.health_check()
    print(f"Status: {health}\n")

if __name__ == "__main__":
    # Para testar, adicione sua API key
    asyncio.run(example_usage())
